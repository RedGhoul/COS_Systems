
CUDA Vs Open CL

In today's high performance computing world there has been a large shift in what components drive the performance of a system. Traditionally the most important part was the central processing unit (CPU), however as Intel and AMD have hit the limits of Moores law. A new technology continues to drive performance gains, that technology being called graphics processing units (GPU). The fundamental difference being that GPUs have thousands of small weak cores, whereas CPUs have a few dozen cores large strong cores. And the way that programs are executed on each of there units. The GPU is designed for highly parallelized computing tasks. Whereas CPUs designed for very linear tasks.
Since the majority of high performance computing deals with numerical approximations, that involve the vectorization of systems of equations. A computing problem can then be broken down into thousands of smaller tasks (such as addition and multiplication) that can be spread across all the cores. However with CPUs the few dozen core get statured with tasks, that leave the other parts of the computation in a queue waiting to be run.

The global leader in GPU technology is Nvidia. Originally their goal was to develop external cards, that could be used render video game geometry with increasing speed and complexity. However in the last decade their focus has now shifted to the development of GPUs in HPC applications. Since there as been an explosion in deep learning and ai research garnered by large technology companies like Amazon, Facebook, and Google.

The adoption of their GPUs as the deep learning standard was made possible by initial release of their CUDA framework, which researcher could use to accelerate there high performance computing tasks. The introduction of CUDA meant that the individuals that used it did not need to know how write multi threaded code. On top of CUDA, Nvidia also developed a large number of highly optimized libraries to do most common commuting tasks (such as matrix multiplication). Which is why a large number of deep learning frameworks run exclusively on Nvidia GPUs. A competitor to Nvidia in the GPU market has been AMD, which has tried to follow Nvidia into the high performance GPU market. AMD has adopted the OpenCL framework that solves the same problems as CUDA, however it is heterogenous to the type of processor it can use. Open GL is open source framework that isn't just for use in any GPU (including Nvidia GPUs), but CPUs as well. As of late, Open GL has yet to gain any traction in the HPC world. Since it is not as fast as CUDA, and the current machine learning libraries do not fully support it.
Therefore we have chosen to work exclusively with Nvidia based GPUs running the latest CUDA drivers, with the newest version of Tensor Flow.
